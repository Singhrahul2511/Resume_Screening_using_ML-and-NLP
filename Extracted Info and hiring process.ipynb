{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25904311",
   "metadata": {},
   "source": [
    "# Extracting Text from Resumes\n",
    "The first step in resume parsing is to extract the text from resumes in various formats, such as PDF or Word documents. We’ll be using the pdfminer.six library to extract text from PDF resumes. Here’s a function that takes a PDF file path as input and returns the extracted text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f471f1d-30f3-4c37-87c6-dc83afea3f95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting pdfminer\n",
      "  Downloading pdfminer-20191125.tar.gz (4.2 MB)\n",
      "     ---------------------------------------- 0.0/4.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/4.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/4.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/4.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/4.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/4.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/4.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/4.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/4.2 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 0.3/4.2 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 0.3/4.2 MB ? eta -:--:--\n",
      "     ----- ---------------------------------- 0.5/4.2 MB 762.0 kB/s eta 0:00:05\n",
      "     ------- -------------------------------- 0.8/4.2 MB 1.0 MB/s eta 0:00:04\n",
      "     ---------- ----------------------------- 1.0/4.2 MB 1.1 MB/s eta 0:00:03\n",
      "     ------------ --------------------------- 1.3/4.2 MB 1.0 MB/s eta 0:00:03\n",
      "     --------------- ------------------------ 1.6/4.2 MB 1.0 MB/s eta 0:00:03\n",
      "     --------------- ------------------------ 1.6/4.2 MB 1.0 MB/s eta 0:00:03\n",
      "     ----------------- ---------------------- 1.8/4.2 MB 967.9 kB/s eta 0:00:03\n",
      "     ----------------- ---------------------- 1.8/4.2 MB 967.9 kB/s eta 0:00:03\n",
      "     -------------------- ------------------- 2.1/4.2 MB 903.5 kB/s eta 0:00:03\n",
      "     ---------------------- ----------------- 2.4/4.2 MB 907.1 kB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 2.4/4.2 MB 907.1 kB/s eta 0:00:02\n",
      "     ------------------------- -------------- 2.6/4.2 MB 926.3 kB/s eta 0:00:02\n",
      "     ------------------------------ --------- 3.1/4.2 MB 976.5 kB/s eta 0:00:02\n",
      "     ------------------------------ --------- 3.1/4.2 MB 976.5 kB/s eta 0:00:02\n",
      "     -------------------------------- ------- 3.4/4.2 MB 932.1 kB/s eta 0:00:01\n",
      "     -------------------------------- ------- 3.4/4.2 MB 932.1 kB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 3.7/4.2 MB 952.5 kB/s eta 0:00:01\n",
      "     ------------------------------------- -- 3.9/4.2 MB 966.6 kB/s eta 0:00:01\n",
      "     ---------------------------------------- 4.2/4.2 MB 962.9 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pycryptodome (from pdfminer)\n",
      "  Downloading pycryptodome-3.21.0-cp36-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Downloading pycryptodome-3.21.0-cp36-abi3-win_amd64.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/1.8 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/1.8 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 0.5/1.8 MB 670.4 kB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 0.5/1.8 MB 670.4 kB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 0.8/1.8 MB 657.8 kB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 0.8/1.8 MB 657.8 kB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 1.0/1.8 MB 671.0 kB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 1.3/1.8 MB 713.8 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.6/1.8 MB 791.5 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.8/1.8 MB 870.7 kB/s eta 0:00:00\n",
      "Building wheels for collected packages: pdfminer\n",
      "  Building wheel for pdfminer (setup.py): started\n",
      "  Building wheel for pdfminer (setup.py): finished with status 'done'\n",
      "  Created wheel for pdfminer: filename=pdfminer-20191125-py3-none-any.whl size=6140156 sha256=7208db0b41abe07b5368988c9d94f23b23b3cb8c30305d9c111ef52a3f6e1354\n",
      "  Stored in directory: c:\\users\\rahul\\appdata\\local\\pip\\cache\\wheels\\90\\7b\\26\\62139fb7c8c5c242c492e02ce8613ca4c3df4cd86afb8e6264\n",
      "Successfully built pdfminer\n",
      "Installing collected packages: pycryptodome, pdfminer\n",
      "Successfully installed pdfminer-20191125 pycryptodome-3.21.0\n"
     ]
    }
   ],
   "source": [
    "pip install pdfminer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bded11ee-523b-4ce2-9adc-b2cbc2438a4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting pdfminer.six\n",
      "  Downloading pdfminer.six-20240706-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\rahul\\appdata\\roaming\\python\\python312\\site-packages (from pdfminer.six) (3.3.2)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\rahul\\appdata\\roaming\\python\\python312\\site-packages (from pdfminer.six) (41.0.7)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\rahul\\appdata\\roaming\\python\\python312\\site-packages (from cryptography>=36.0.0->pdfminer.six) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\rahul\\appdata\\roaming\\python\\python312\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.21)\n",
      "Downloading pdfminer.six-20240706-py3-none-any.whl (5.6 MB)\n",
      "   ---------------------------------------- 0.0/5.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/5.6 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.8/5.6 MB 8.5 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.8/5.6 MB 8.5 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 1.3/5.6 MB 2.4 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 1.3/5.6 MB 2.4 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 2.4/5.6 MB 2.5 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 3.4/5.6 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 4.5/5.6 MB 2.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 4.7/5.6 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 5.2/5.6 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 5.2/5.6 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.6/5.6 MB 2.4 MB/s eta 0:00:00\n",
      "Installing collected packages: pdfminer.six\n",
      "Successfully installed pdfminer.six-20240706\n"
     ]
    }
   ],
   "source": [
    "pip install pdfminer.six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53e123ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rahul Kumar\\n\\nAurangabad,Bihar\\n(cid:211) +91-7033810323  99220042041@klu.ac.in  Linkedin (cid:135) Github ¡ Instagram\\n\\nEDUCATION\\nKARE, Kalasalingam Academy of Research and Education, Tamilnadu\\nB.Tech - Computer Science and Engineering - CGPA - 8.19\\n\\n2022 – 2026\\nKrishnankovil, Tamilnadu\\n\\nCOURSEWORK / SKILLS\\n\\n• Basics of Database\\n\\nManagement System\\n\\n(DBMS)\\n\\n• Machine\\n\\nLearning(Medium)\\n\\n• Python(Medium)\\n\\nEXPERIENCE\\n\\nNo Work Experience  |\\nTECHNICAL SKILLS\\n\\nLanguages: Python,Artificial Intelligence,Machine Learning\\nDeveloper Tools: VS Code, Git/Github\\n\\nCoding Platforms\\n\\n∗ Hackerrank: 50+ Rating, Solved 100+ Problems \\n∗ Codechef: Solved 50+ Problems \\n\\nCERTIFICATIONS\\n\\n• Oracle Cloud Infrastructure 2023 AI Foundations Associate-Oracle\\n• • Data-Visualization Using Plotly-Udemy\\n• Soft Skill - NPTEL(IIT Roorkee)\\n• Code Chef - DBMS\\n\\nEXTRACURRICULAR\\n\\n∗ Passionate to play cricket till 2015\\n\\n\\x0c'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    return extract_text(pdf_path)\n",
    "\n",
    "\n",
    "resume_path = \"Resume_Rahul_updated.pdf\"\n",
    "text = extract_text_from_pdf(resume_path)\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3869cab2",
   "metadata": {},
   "source": [
    "# Extracting Contact Information\n",
    "\n",
    "\n",
    "Contact information, including phone numbers, email addresses, and physical addresses, is crucial for reaching out to potential candidates. Extracting this information accurately is an essential part of resume parsing. We can use regular expressions to match patterns and extract contact information.\n",
    "\n",
    "# Function to Extract\n",
    "\n",
    "\n",
    "Let’s define a function to extract a contact number from the resume text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4795cd19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'91-7033810323'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_contact_number_from_resume(text):\n",
    "    contact_number = None\n",
    "\n",
    "    # Use regex pattern to find a potential contact number\n",
    "    pattern = r\"\\b(?:\\+?\\d{1,3}[-.\\s]?)?\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}\\b\"\n",
    "    match = re.search(pattern, text)\n",
    "    if match:\n",
    "        contact_number = match.group()\n",
    "\n",
    "    return contact_number\n",
    "\n",
    "phone = extract_contact_number_from_resume(text)\n",
    "phone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ce6ac7",
   "metadata": {},
   "source": [
    "# Extracting Email Address\n",
    "In addition to the contact number, extracting the email address is vital for communication with candidates. We can again use regular expressions to match patterns and extract the email address. Here’s a function to extract the email address from the resume text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bc1e09c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'99220042041@klu.ac.in'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_email_from_resume(text):\n",
    "    email = None\n",
    "\n",
    "    # Use regex pattern to find a potential email address\n",
    "    pattern = r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\\b\"\n",
    "    match = re.search(pattern, text)\n",
    "    if match:\n",
    "        email = match.group()\n",
    "\n",
    "    return email\n",
    "\n",
    "email = extract_email_from_resume(text)\n",
    "email"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74a16b8",
   "metadata": {},
   "source": [
    "# Extracting Skills\n",
    "Identifying the skills mentioned in a resume is crucial for determining the candidate’s qualifications. We can create a list of relevant skills and match them against the resume text to extract the mentioned skills. Let’s define a function to extract skills from the resume text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbb25dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skills: ['Python', 'Machine Learning', 'Git', 'Research', 'Plotly', 'Oracle']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_skills_from_resume(text, skills_list):\n",
    "    skills = []\n",
    "\n",
    "    for skill in skills_list:\n",
    "        pattern = r\"\\b{}\\b\".format(re.escape(skill))\n",
    "        match = re.search(pattern, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            skills.append(skill)\n",
    "\n",
    "    return skills\n",
    "\n",
    "\n",
    "# List of predefined skills\n",
    "skills_list = [\n",
    "    'Python', 'Data Analysis', 'Machine Learning', 'Communication', 'Project Management', 'Deep Learning', 'SQL', 'Tableau',\n",
    "    'Java', 'C++', 'JavaScript', 'HTML', 'CSS', 'React', 'Angular', 'Node.js', 'MongoDB', 'Express.js', 'Git',\n",
    "    'Research', 'Statistics', 'Quantitative Analysis', 'Qualitative Analysis', 'SPSS', 'R', 'Data Visualization', 'Matplotlib',\n",
    "    'Seaborn', 'Plotly', 'Pandas', 'Numpy', 'Scikit-learn', 'TensorFlow', 'Keras', 'PyTorch', 'NLTK', 'Text Mining',\n",
    "    'Natural Language Processing', 'Computer Vision', 'Image Processing', 'OCR', 'Speech Recognition', 'Recommendation Systems',\n",
    "    'Collaborative Filtering', 'Content-Based Filtering', 'Reinforcement Learning', 'Neural Networks', 'Convolutional Neural Networks',\n",
    "    'Recurrent Neural Networks', 'Generative Adversarial Networks', 'XGBoost', 'Random Forest', 'Decision Trees', 'Support Vector Machines',\n",
    "    'Linear Regression', 'Logistic Regression', 'K-Means Clustering', 'Hierarchical Clustering', 'DBSCAN', 'Association Rule Learning',\n",
    "    'Apache Hadoop', 'Apache Spark', 'MapReduce', 'Hive', 'HBase', 'Apache Kafka', 'Data Warehousing', 'ETL', 'Big Data Analytics',\n",
    "    'Cloud Computing', 'Amazon Web Services (AWS)', 'Microsoft Azure', 'Google Cloud Platform (GCP)', 'Docker', 'Kubernetes', 'Linux',\n",
    "    'Shell Scripting', 'Cybersecurity', 'Network Security', 'Penetration Testing', 'Firewalls', 'Encryption', 'Malware Analysis',\n",
    "    'Digital Forensics', 'CI/CD', 'DevOps', 'Agile Methodology', 'Scrum', 'Kanban', 'Continuous Integration', 'Continuous Deployment',\n",
    "    'Software Development', 'Web Development', 'Mobile Development', 'Backend Development', 'Frontend Development', 'Full-Stack Development',\n",
    "    'UI/UX Design', 'Responsive Design', 'Wireframing', 'Prototyping', 'User Testing', 'Adobe Creative Suite', 'Photoshop', 'Illustrator',\n",
    "    'InDesign', 'Figma', 'Sketch', 'Zeplin', 'InVision', 'Product Management', 'Market Research', 'Customer Development', 'Lean Startup',\n",
    "    'Business Development', 'Sales', 'Marketing', 'Content Marketing', 'Social Media Marketing', 'Email Marketing', 'SEO', 'SEM', 'PPC',\n",
    "    'Google Analytics', 'Facebook Ads', 'LinkedIn Ads', 'Lead Generation', 'Customer Relationship Management (CRM)', 'Salesforce',\n",
    "    'HubSpot', 'Zendesk', 'Intercom', 'Customer Support', 'Technical Support', 'Troubleshooting', 'Ticketing Systems', 'ServiceNow',\n",
    "    'ITIL', 'Quality Assurance', 'Manual Testing', 'Automated Testing', 'Selenium', 'JUnit', 'Load Testing', 'Performance Testing',\n",
    "    'Regression Testing', 'Black Box Testing', 'White Box Testing', 'API Testing', 'Mobile Testing', 'Usability Testing', 'Accessibility Testing',\n",
    "    'Cross-Browser Testing', 'Agile Testing', 'User Acceptance Testing', 'Software Documentation', 'Technical Writing', 'Copywriting',\n",
    "    'Editing', 'Proofreading', 'Content Management Systems (CMS)', 'WordPress', 'Joomla', 'Drupal', 'Magento', 'Shopify', 'E-commerce',\n",
    "    'Payment Gateways', 'Inventory Management', 'Supply Chain Management', 'Logistics', 'Procurement', 'ERP Systems', 'SAP', 'Oracle',\n",
    "    'Microsoft Dynamics', 'Tableau', 'Power BI', 'QlikView', 'Looker', 'Data Warehousing', 'ETL', 'Data Engineering', 'Data Governance',\n",
    "    'Data Quality', 'Master Data Management', 'Predictive Analytics', 'Prescriptive Analytics', 'Descriptive Analytics', 'Business Intelligence',\n",
    "    'Dashboarding', 'Reporting', 'Data Mining', 'Web Scraping', 'API Integration', 'RESTful APIs', 'GraphQL', 'SOAP', 'Microservices',\n",
    "    'Serverless Architecture', 'Lambda Functions', 'Event-Driven Architecture', 'Message Queues', 'GraphQL', 'Socket.io', 'WebSockets'\n",
    "'Ruby', 'Ruby on Rails', 'PHP', 'Symfony', 'Laravel', 'CakePHP', 'Zend Framework', 'ASP.NET', 'C#', 'VB.NET', 'ASP.NET MVC', 'Entity Framework',\n",
    "    'Spring', 'Hibernate', 'Struts', 'Kotlin', 'Swift', 'Objective-C', 'iOS Development', 'Android Development', 'Flutter', 'React Native', 'Ionic',\n",
    "    'Mobile UI/UX Design', 'Material Design', 'SwiftUI', 'RxJava', 'RxSwift', 'Django', 'Flask', 'FastAPI', 'Falcon', 'Tornado', 'WebSockets',\n",
    "    'GraphQL', 'RESTful Web Services', 'SOAP', 'Microservices Architecture', 'Serverless Computing', 'AWS Lambda', 'Google Cloud Functions',\n",
    "    'Azure Functions', 'Server Administration', 'System Administration', 'Network Administration', 'Database Administration', 'MySQL', 'PostgreSQL',\n",
    "    'SQLite', 'Microsoft SQL Server', 'Oracle Database', 'NoSQL', 'MongoDB', 'Cassandra', 'Redis', 'Elasticsearch', 'Firebase', 'Google Analytics',\n",
    "    'Google Tag Manager', 'Adobe Analytics', 'Marketing Automation', 'Customer Data Platforms', 'Segment', 'Salesforce Marketing Cloud', 'HubSpot CRM',\n",
    "    'Zapier', 'IFTTT', 'Workflow Automation', 'Robotic Process Automation (RPA)', 'UI Automation', 'Natural Language Generation (NLG)',\n",
    "    'Virtual Reality (VR)', 'Augmented Reality (AR)', 'Mixed Reality (MR)', 'Unity', 'Unreal Engine', '3D Modeling', 'Animation', 'Motion Graphics',\n",
    "    'Game Design', 'Game Development', 'Level Design', 'Unity3D', 'Unreal Engine 4', 'Blender', 'Maya', 'Adobe After Effects', 'Adobe Premiere Pro',\n",
    "    'Final Cut Pro', 'Video Editing', 'Audio Editing', 'Sound Design', 'Music Production', 'Digital Marketing', 'Content Strategy', 'Conversion Rate Optimization (CRO)',\n",
    "    'A/B Testing', 'Customer Experience (CX)', 'User Experience (UX)', 'User Interface (UI)', 'Persona Development', 'User Journey Mapping', 'Information Architecture (IA)',\n",
    "    'Wireframing', 'Prototyping', 'Usability Testing', 'Accessibility Compliance', 'Internationalization (I18n)', 'Localization (L10n)', 'Voice User Interface (VUI)',\n",
    "    'Chatbots', 'Natural Language Understanding (NLU)', 'Speech Synthesis', 'Emotion Detection', 'Sentiment Analysis', 'Image Recognition', 'Object Detection',\n",
    "    'Facial Recognition', 'Gesture Recognition', 'Document Recognition', 'Fraud Detection', 'Cyber Threat Intelligence', 'Security Information and Event Management (SIEM)',\n",
    "    'Vulnerability Assessment', 'Incident Response', 'Forensic Analysis', 'Security Operations Center (SOC)', 'Identity and Access Management (IAM)', 'Single Sign-On (SSO)',\n",
    "    'Multi-Factor Authentication (MFA)', 'Blockchain', 'Cryptocurrency', 'Decentralized Finance (DeFi)', 'Smart Contracts', 'Web3', 'Non-Fungible Tokens (NFTs)']\n",
    "\n",
    "extracted_skills = extract_skills_from_resume(text, skills_list)\n",
    "\n",
    "if extracted_skills:\n",
    "    print(\"Skills:\", extracted_skills)\n",
    "else:\n",
    "    print(\"No skills found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfb5931",
   "metadata": {},
   "source": [
    "# Extracting Education\n",
    "Education qualifications play a vital role in the recruitment process. We can match specific education keywords against the resume text to identify the candidate’s educational background. Here’s a function to extract education information from the resume text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "544f6bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Education: ['Computer Science', 'Management', 'EDUCATION']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_education_from_resume(text):\n",
    "    education = []\n",
    "\n",
    "    # List of education keywords to match against\n",
    "    education_keywords = [\n",
    "        'Computer Science', 'Information Technology', 'Software Engineering', 'Electrical Engineering', 'Mechanical Engineering', 'Civil Engineering',\n",
    "        'Chemical Engineering', 'Biomedical Engineering', 'Aerospace Engineering', 'Nuclear Engineering', 'Industrial Engineering', 'Systems Engineering',\n",
    "        'Environmental Engineering', 'Petroleum Engineering', 'Geological Engineering', 'Marine Engineering', 'Robotics Engineering', 'Biotechnology',\n",
    "        'Biochemistry', 'Microbiology', 'Genetics', 'Molecular Biology', 'Bioinformatics', 'Neuroscience', 'Biophysics', 'Biostatistics', 'Pharmacology',\n",
    "        'Physiology', 'Anatomy', 'Pathology', 'Immunology', 'Epidemiology', 'Public Health', 'Health Administration', 'Nursing', 'Medicine', 'Dentistry',\n",
    "        'Pharmacy', 'Veterinary Medicine', 'Medical Technology', 'Radiography', 'Physical Therapy', 'Occupational Therapy', 'Speech Therapy', 'Nutrition',\n",
    "        'Sports Science', 'Kinesiology', 'Exercise Physiology', 'Sports Medicine', 'Rehabilitation Science', 'Psychology', 'Counseling', 'Social Work',\n",
    "        'Sociology', 'Anthropology', 'Criminal Justice', 'Political Science', 'International Relations', 'Economics', 'Finance', 'Accounting', 'Business Administration',\n",
    "        'Management', 'Marketing', 'Entrepreneurship', 'Hospitality Management', 'Tourism Management', 'Supply Chain Management', 'Logistics Management',\n",
    "        'Operations Management', 'Human Resource Management', 'Organizational Behavior', 'Project Management', 'Quality Management', 'Risk Management',\n",
    "        'Strategic Management', 'Public Administration', 'Urban Planning', 'Architecture', 'Interior Design', 'Landscape Architecture', 'Fine Arts',\n",
    "        'Visual Arts', 'Graphic Design', 'Fashion Design', 'Industrial Design', 'Product Design', 'Animation', 'Film Studies', 'Media Studies',\n",
    "        'Communication Studies', 'Journalism', 'Broadcasting', 'Creative Writing', 'English Literature', 'Linguistics', 'Translation Studies',\n",
    "        'Foreign Languages', 'Modern Languages', 'Classical Studies', 'History', 'Archaeology', 'Philosophy', 'Theology', 'Religious Studies',\n",
    "        'Ethics', 'Education', 'Early Childhood Education', 'Elementary Education', 'Secondary Education', 'Special Education', 'Higher Education',\n",
    "        'Adult Education', 'Distance Education', 'Online Education', 'Instructional Design', 'Curriculum Development'\n",
    "        'Library Science', 'Information Science', 'Computer Engineering', 'Software Development', 'Cybersecurity', 'Information Security',\n",
    "        'Network Engineering', 'Data Science', 'Data Analytics', 'Business Analytics', 'Operations Research', 'Decision Sciences',\n",
    "        'Human-Computer Interaction', 'User Experience Design', 'User Interface Design', 'Digital Marketing', 'Content Strategy',\n",
    "        'Brand Management', 'Public Relations', 'Corporate Communications', 'Media Production', 'Digital Media', 'Web Development',\n",
    "        'Mobile App Development', 'Game Development', 'Virtual Reality', 'Augmented Reality', 'Blockchain Technology', 'Cryptocurrency',\n",
    "        'Digital Forensics', 'Forensic Science', 'Criminalistics', 'Crime Scene Investigation', 'Emergency Management', 'Fire Science',\n",
    "        'Environmental Science', 'Climate Science', 'Meteorology', 'Geography', 'Geomatics', 'Remote Sensing', 'Geoinformatics',\n",
    "        'Cartography', 'GIS (Geographic Information Systems)', 'Environmental Management', 'Sustainability Studies', 'Renewable Energy',\n",
    "        'Green Technology', 'Ecology', 'Conservation Biology', 'Wildlife Biology', 'Zoology']\n",
    "\n",
    "    for keyword in education_keywords:\n",
    "        pattern = r\"(?i)\\b{}\\b\".format(re.escape(keyword))\n",
    "        match = re.search(pattern, text)\n",
    "        if match:\n",
    "            education.append(match.group())\n",
    "\n",
    "    return education\n",
    "\n",
    "extracted_education = extract_education_from_resume(text)\n",
    "if extracted_education:\n",
    "    print(\"Education:\", extracted_education)\n",
    "else:\n",
    "    print(\"No education information found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0951159a",
   "metadata": {},
   "source": [
    "# Extracting Name Using spaCy\n",
    "Identifying the candidate’s name from the resume is essential for personalization and identification. We can use spaCy and its pattern matching capabilities to extract the candidate’s name. Let’s define a function to extract the name using spaCy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9c0bf68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Rahul Kumar\n"
     ]
    }
   ],
   "source": [
    "def extract_name_from_resume(text):\n",
    "    name = None\n",
    "\n",
    "    # Use regex pattern to find a potential name\n",
    "    pattern = r\"(\\b[A-Z][a-z]+\\b)\\s(\\b[A-Z][a-z]+\\b)\"\n",
    "    match = re.search(pattern, text)\n",
    "    if match:\n",
    "        name = match.group()\n",
    "\n",
    "    return name\n",
    "\n",
    "name = extract_name_from_resume(text)\n",
    "\n",
    "if name:\n",
    "    print(\"Name:\", name)\n",
    "else:\n",
    "    print(\"Name not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420503a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
